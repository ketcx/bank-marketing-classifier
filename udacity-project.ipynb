{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Classification of clients of a bank's marketing campaign\n",
    "\n",
    "## Armando Medina\n",
    "    \n",
    "#### (October, 2020)\n",
    "</center>\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1603409477979
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "#ws = Workspace.get(name=\"quick-starts-ws-122643\")\n",
    "ws = Workspace.get(name=\"Experiments\")\n",
    "\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1603409614196
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "#cpu_cluster_name = \"udacity-first-project\"\n",
    "cpu_cluster_name = \"TheGPUMachine\"\n",
    "\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"Standard_D2_V2\", max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1603412966872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive import choice\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "    'C': uniform(0.01, 100),\n",
    "    'max_iter': choice(100, 1000, 10000)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1) \n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "    \n",
    "azureml_pip_packages = [\n",
    "    'azureml-defaults', 'azureml-contrib-interpret', 'azureml-telemetry', 'azureml-interpret'\n",
    "]\n",
    "    \n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "est = SKLearn(entry_script='./train.py', source_directory=\".\", compute_target=cpu_cluster, pip_packages=azureml_pip_packages)\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(estimator=est,\n",
    "                                     hyperparameter_sampling=ps,\n",
    "                                     policy=policy,\n",
    "                                     primary_metric_name='Accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=4,\n",
    "                                     max_concurrent_runs=4\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"hyperparamenter_tuning\")\n",
    "run = experiment.submit(config=hyperdrive_config, show_output=True)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "# Get your best run and save the model from that run.\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "\n",
    "model = best_run.register_model(model_name='sklearn-lr', \n",
    "                                model_path='./outputs/model.joblib', \n",
    "                                model_framework=Model.Framework.SCIKITLEARN, \n",
    "                                model_framework_version='0.22.2',\n",
    "                                resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=7.0)\n",
    "                               )\n",
    "\n",
    "print(best_run.get_metrics())\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from cleandata import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "ds = TabularDatasetFactory.from_delimited_files(\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\", validate=True, include_path=False, infer_column_types=True, set_column_types=None, separator=',', header=True, partition_format=None, support_multi_line=False, empty_as_string=False)\n",
    "x, y = clean_data(ds)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42);\n",
    "\n",
    "model.download(target_dir='outputs/', exist_ok=False, exists_ok=None)\n",
    "\n",
    "#model\n",
    "lr_model = joblib.load('outputs/model.joblib')\n",
    "\n",
    "\n",
    "#prediction\n",
    "predictions = lr_model.predict(x_test)\n",
    "#score\n",
    "score = lr_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cm/np.sum(cm), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "ds = TabularDatasetFactory.from_delimited_files(\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\", validate=True, include_path=False, infer_column_types=True, set_column_types=None, separator=',', header=True, partition_format=None, support_multi_line=False, empty_as_string=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from cleandata import clean_data\n",
    "import os\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(ds)\n",
    "feature_names = list(x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --upgrade-strategy eager azureml-sdk azureml-contrib-explain-model azureml-interpret \n",
    "#!pip install azureml-contrib-explain-model==1.0.65 --force-reinstall\n",
    "!pip install -U scikit-learn==0.22.2.post1 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from azureml.contrib.interpret.explanation.explanation_client import ExplanationClient\n",
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "client = ExplanationClient.from_run(best_run)\n",
    "global_explanation = client.download_model_explanation(top_k=5)\n",
    "local_importance_values = global_explanation.local_importance_values\n",
    "expected_values = global_explanation.expected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_explanation_topk = client.download_model_explanation(top_k=5)\n",
    "global_importance_values = global_explanation_topk.get_ranked_global_values()\n",
    "global_importance_names = global_explanation_topk.get_ranked_global_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('global importance values: {}'.format(global_importance_values))\n",
    "print('global importance names: {}'.format(global_importance_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "import joblib\n",
    "original_model = Model(ws, 'sklearn-lr')\n",
    "model_path = original_model.download(exist_ok=True)\n",
    "original_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.data.dataset_factory import DataType\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "df = TabularDatasetFactory.from_delimited_files(\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\", validate=True, include_path=False, infer_column_types=True, set_column_types=None, separator=',', header=True, partition_format=None, support_multi_line=False, empty_as_string=False)\n",
    "\n",
    "x_automl, y_automl = clean_data(df)\n",
    "\n",
    "data_train = x_automl\n",
    "data_train['y'] = y_automl\n",
    "feature_names = list(data_train.columns)\n",
    "\n",
    "if \"data\" not in os.listdir():\n",
    "    os.mkdir(\"./data\")\n",
    "\n",
    "local_path = './data/data_clean.csv'\n",
    "data_train.to_csv(local_path)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "datastore.upload(src_dir='data', target_path='data')\n",
    "\n",
    "datastore_paths = [(datastore, 'data/data_clean.csv')]\n",
    "\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=datastore_paths)\n",
    "\n",
    "training_data, validation_data = dataset.random_split(percentage=0.8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             experiment_timeout_minutes=30,\n",
    "                             primary_metric_name='accuracy',\n",
    "                             blocked_models=['XGBoostClassifier', 'MaxAbsScaler SVM'],\n",
    "                             training_data=training_data,\n",
    "                             validation_data= validation_data,\n",
    "                             label_column_name = 'y',\n",
    "                             compute_target=cpu_cluster\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your automl run\n",
    "automl_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(automl_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "# Get your best run and save the model from that run.\n",
    "best_run, fitted_model = automl_run.get_output(metric = \"accuracy\")\n",
    "print(best_run)\n",
    "\n",
    "\n",
    "description = 'Best AutoML Model'\n",
    "tags = None\n",
    "model = automl_run.register_model(description = description, tags = tags)\n",
    "print(automl_run.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fitted_model:\\n {}\\n\\n'.format(fitted_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle imbalanced data\n",
    "\n",
    "The variable y is extremely unbalanced, this causes bias, this can be seen in the confusion matrix.\n",
    "\n",
    "In the handle-imbalanced-data.ipynb notebook included in this project, you can see how the problem is corrected and the dataset is created through the Synthetic Minority Oversampling Technique, or SMOTE for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['No', 'Yes'], data_train.y.value_counts().values, facecolor = 'lawngreen', edgecolor='lightseagreen', linewidth=0.5)\n",
    "plt.title('Has the client subscribed a term deposit?', fontsize=14)\n",
    "plt.xlabel('Answer')\n",
    "plt.ylabel('No.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_training_paths = [(datastore, 'data/data_balanced.csv')]\n",
    "datastore_validation_paths = [(datastore, 'data/data_validation.csv')]\n",
    "\n",
    "training_dataset = Dataset.Tabular.from_delimited_files(path=datastore_training_paths)\n",
    "validation_dataset = Dataset.Tabular.from_delimited_files(path=datastore_validation_paths)\n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             experiment_timeout_minutes=30,\n",
    "                             primary_metric_name='accuracy',\n",
    "                             blocked_models=['XGBoostClassifier', 'MaxAbsScaler SVM'],\n",
    "                             training_data=training_dataset,\n",
    "                             validation_data= validation_dataset,\n",
    "                             label_column_name = 'y',\n",
    "                             compute_target=cpu_cluster\n",
    "                            )\n",
    "\n",
    "automl_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(automl_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "# Get your best run and save the model from that run.\n",
    "best_run, fitted_model = automl_run.get_output(metric = \"accuracy\")\n",
    "print(best_run)\n",
    "\n",
    "\n",
    "description = 'Best AutoML Model'\n",
    "tags = None\n",
    "model = automl_run.register_model(description = description, tags = tags)\n",
    "print(automl_run.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive import choice\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "    'C': uniform(0.01, 100),\n",
    "    'max_iter': choice(100, 1000, 10000)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1) \n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "    \n",
    "azureml_pip_packages = [\n",
    "    'azureml-defaults', 'azureml-contrib-interpret', 'azureml-telemetry', 'azureml-interpret'\n",
    "]\n",
    "    \n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "est = SKLearn(entry_script='./train_balanced.py', source_directory=\".\", compute_target=cpu_cluster, pip_packages=azureml_pip_packages)\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(estimator=est,\n",
    "                                     hyperparameter_sampling=ps,\n",
    "                                     policy=policy,\n",
    "                                     primary_metric_name='Accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=4,\n",
    "                                     max_concurrent_runs=4\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"hyperparamenter_tuning\")\n",
    "run = experiment.submit(config=hyperdrive_config, show_output=True)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "# Get your best run and save the model from that run.\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "\n",
    "model = best_run.register_model(model_name='sklearn-lr', \n",
    "                                model_path='./outputs/model.joblib', \n",
    "                                model_framework=Model.Framework.SCIKITLEARN, \n",
    "                                model_framework_version='0.22.2',\n",
    "                                resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=7.0)\n",
    "                               )\n",
    "\n",
    "\n",
    "model.download(target_dir='outputs/', exist_ok=True, exists_ok=None)\n",
    "\n",
    "#model\n",
    "lr_model = joblib.load('outputs/model.joblib')\n",
    "\n",
    "#data\n",
    "data_test = pd.read_csv('data/data_validation.csv')  \n",
    "\n",
    "y_test = data_test[\"y\"]\n",
    "data_test.drop(\"y\", inplace=True, axis=1)\n",
    "data_test.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "x_test = data_test\n",
    "\n",
    "\n",
    "#prediction\n",
    "predictions = lr_model.predict(x_test)\n",
    "#score\n",
    "score = lr_model.score(x_test, y_test)\n",
    "#confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cm/np.sum(cm), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu_cluster.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
